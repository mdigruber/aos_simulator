{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### Make sure the file is executed from the LFR/python directory\n",
    "\n",
    "## Import libraries section ##\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import math\n",
    "import re\n",
    "from LFR_utils import read_poses_and_images,pose_to_virtualcamera, init_aos, init_window\n",
    "import LFR_utils as utils\n",
    "import pyaos\n",
    "import glm\n",
    "import glob\n",
    "from PIL import Image\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = r'/home/mdigruber/AOS/AOS for Drone Swarms/LFR/data/img_markus'    ## Enter path to where your images are saved.\n",
    "result_path = r'/home/mdigruber/AOS/AOS for Drone Swarms/LFR/data/FP'      ## Enter path to where you want the results to be saved.\n",
    "set_folder = r'/home/mdigruber/AOS/AOS for Drone Swarms/LFR/python'      ## Enter path to your LFR/python directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "Focal_plane = 35  # Focal plane is set to the ground so it is zero.  \n",
    "\n",
    "altitude_list = [35.01]   # Metion the altitude (all drones are in the same altitude)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,h,fovDegrees = 512, 512, 35 # # resolution and field of view. This should not be changed.\n",
    "render_fov = 35\n",
    "\n",
    "if 'window' not in locals() or window == None:\n",
    "                                    \n",
    "    window = pyaos.PyGlfwWindow( w, h, 'AOS' )  \n",
    "     \n",
    "aos = pyaos.PyAOS(w,h,fovDegrees) \n",
    "\n",
    "aos.loadDEM( os.path.join(set_folder,'zero_plane.obj'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############################Create Poses for Initial Positions###############################################################\n",
    "\n",
    "# Below are certain functions required to convert the poses to a certain format to be compatabile with the AOS Renderer.\n",
    "\n",
    "def eul2rotm(theta) :\n",
    "    s_1 = math.sin(theta[0])\n",
    "    c_1 = math.cos(theta[0]) \n",
    "    s_2 = math.sin(theta[1]) \n",
    "    c_2 = math.cos(theta[1]) \n",
    "    s_3 = math.sin(theta[2]) \n",
    "    c_3 = math.cos(theta[2])\n",
    "    rotm = np.identity(3)\n",
    "    rotm[0,0] =  c_1*c_2\n",
    "    rotm[0,1] =  c_1*s_2*s_3 - s_1*c_3\n",
    "    rotm[0,2] =  c_1*s_2*c_3 + s_1*s_3\n",
    "\n",
    "    rotm[1,0] =  s_1*c_2\n",
    "    rotm[1,1] =  s_1*s_2*s_3 + c_1*c_3\n",
    "    rotm[1,2] =  s_1*s_2*c_3 - c_1*s_3\n",
    "\n",
    "    rotm[2,0] = -s_2\n",
    "    rotm[2,1] =  c_2*s_3\n",
    "    rotm[2,2] =  c_2*c_3        \n",
    "\n",
    "    return rotm\n",
    "\n",
    "def createviewmateuler(eulerang, camLocation):\n",
    "    \n",
    "    rotationmat = eul2rotm(eulerang)\n",
    "    translVec =  np.reshape((-camLocation @ rotationmat),(3,1))\n",
    "    conjoinedmat = (np.append(np.transpose(rotationmat), translVec, axis=1))\n",
    "    return conjoinedmat\n",
    "\n",
    "def divide_by_alpha(rimg2):\n",
    "        a = np.stack((rimg2[:,:,3],rimg2[:,:,3],rimg2[:,:,3]),axis=-1)\n",
    "        return rimg2[:,:,:3]/a\n",
    "    \n",
    "    \n",
    "def pose_to_virtualcamera(vpose ):\n",
    "    vp = glm.mat4(*np.array(vpose).transpose().flatten())\n",
    "    #vp = vpose.copy()\n",
    "    ivp = glm.inverse(glm.transpose(vp))\n",
    "    #ivp = glm.inverse(vpose)\n",
    "    Posvec = glm.vec3(ivp[3])\n",
    "    Upvec = glm.vec3(ivp[1])\n",
    "    FrontVec = glm.vec3(ivp[2])\n",
    "    lookAt = glm.lookAt(Posvec, Posvec + FrontVec, Upvec)\n",
    "    cameraviewarr = np.asarray(lookAt)\n",
    "    #print(cameraviewarr)\n",
    "    return cameraviewarr \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40\n",
      "xposes: [-15.0, -11.25, -7.5, -3.75, 0.0, 3.75, 7.5, 11.25, 15.0, -15.0, -11.25, -7.5, -3.75, 0.0, 3.75, 7.5, 11.25, 15.0, -15.0, -11.25, -7.5, -3.75, 0.0, 3.75, 7.5, 11.25, 15.0, -15.0, -11.25, -7.5, -3.75, 0.0, 3.75, 7.5, 11.25, 15.0, -15.0, -11.25, -7.5, -3.75, 0.0, 3.75, 7.5, 11.25, 15.0, -15.0, -11.25, -7.5, -3.75, 0.0, 3.75, 7.5, 11.25, 15.0, -15.0, -11.25, -7.5, -3.75, 0.0, 3.75, 7.5, 11.25, 15.0, -15.0, -11.25, -7.5, -3.75, 0.0, 3.75, 7.5, 11.25, 15.0, -15.0, -11.25, -7.5, -3.75, 0.0, 3.75, 7.5, 11.25, 15.0]\n",
      "yposes: [15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 15.0, 11.25, 11.25, 11.25, 11.25, 11.25, 11.25, 11.25, 11.25, 11.25, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 7.5, 3.75, 3.75, 3.75, 3.75, 3.75, 3.75, 3.75, 3.75, 3.75, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -0.0, -3.75, -3.75, -3.75, -3.75, -3.75, -3.75, -3.75, -3.75, -3.75, -7.5, -7.5, -7.5, -7.5, -7.5, -7.5, -7.5, -7.5, -7.5, -11.25, -11.25, -11.25, -11.25, -11.25, -11.25, -11.25, -11.25, -11.25, -15.0, -15.0, -15.0, -15.0, -15.0, -15.0, -15.0, -15.0, -15.0]\n",
      "0.0 -0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "81"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "# grid_resolution = 31  # Mention the same grid size that was mentioned in the simulator for simulation.\n",
    "\n",
    "# area_size =  30    # The range is  -16.32 to 16.32 just as mentioned in the simulator for image generation \n",
    "\n",
    "grid_resolution = 9  # Mention the same grid size that was mentioned in the simulator for simulation.\n",
    "\n",
    "area_size =  15    # The range is  -16.32 to 16.32 just as mentioned in the simulator for image generation \n",
    "\n",
    "image_posx_1 = []\n",
    "image_posy_1 = []\n",
    "\n",
    "image_posx = []\n",
    "image_posy = []\n",
    "\n",
    "grid_size= int((grid_resolution-1)/2)\n",
    "\n",
    "numbers = [random.uniform(0.1, 0.5) for _ in range(10)]\n",
    "\n",
    "# Below we compute the poses (x and y coordinates in metres as in simulation)\n",
    "c = 0\n",
    "for y in range( -grid_size,grid_size+1,1):\n",
    "    for x in range(-grid_size,grid_size+1, 1):\n",
    "        image_posx.append((x*area_size/grid_size))\n",
    "        image_posy.append(-(y*area_size/grid_size))\n",
    "        if (x*area_size/grid_size) == 0 and -(y*area_size/grid_size) == 0:\n",
    "            print(c)\n",
    "        c += 1\n",
    "\n",
    "# for i in range(0, len(image_posx_1), 12):\n",
    "#     image_posx.append(image_posx_1[i])\n",
    "\n",
    "# for i in range(0, len(image_posy_1), 12):\n",
    "#     image_posy.append(image_posy_1[i])\n",
    "       \n",
    "print('xposes:',image_posx)\n",
    "print('yposes:',image_posy)\n",
    "print(image_posx[len(image_posx) //2], image_posy[len(image_posx) //2])\n",
    "len(image_posx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-10.0\n",
      "[30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -0.0, -1.0, -2.0, -3.0, -4.0, -5.0, -6.0, -7.0, -8.0, -9.0, -10.0, -11.0, -12.0, -13.0, -14.0, -15.0, -16.0, -17.0, -18.0, -19.0, -20.0, -21.0, -22.0, -23.0, -24.0, -25.0, -26.0, -27.0, -28.0, -29.0]\n",
      "[-35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0, -35.0]\n"
     ]
    }
   ],
   "source": [
    "with open(r'/home/mdigruber/AOS/AOS for Drone Swarms/LFR/data/poses.txt', 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    \n",
    "image_posx = []\n",
    "image_posy = []\n",
    "image_posz = []\n",
    "\n",
    "for line in lines:\n",
    "    image_posx.append(float(line.split(',')[0]) * -1)\n",
    "    image_posy.append(float(line.split(',')[1]) * -1)\n",
    "    image_posz.append(float(line.split(',')[2]) * -1)\n",
    "\n",
    "# image_posz = image_posz * -1\n",
    "print(image_posx[len(lines)//2])\n",
    "print(image_posy)\n",
    "print(image_posz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "start_time = time.time()\n",
    "# Below is a function to sort the image while loading from the folder\n",
    "numbers = re.compile(r'(\\d+)')\n",
    "def numericalSort(value):\n",
    "    parts = numbers.split(value)\n",
    "    parts[1::2] = map(int, parts[1::2])\n",
    "    return parts\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This cell generate the grid for low-resolution sapmles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "data = []\n",
    "for img in range(0, len(sorted(glob.glob(folder_path + '/*.png'),key=numericalSort)), 12): \n",
    "    shutil.copy(r\"d:\\Research\\De-Blurring\\codes\\SOD-Pytorch\\data\\test\\Scene_41\\FS\\TD_pose_\"+str(img)+\"_rgb.png\", \n",
    "                r\"d:\\Research\\De-Blurring\\codes\\SOD-Pytorch\\data\\test\\Scene_41\\FS_9\\TD_pose_\"+str(img)+\"_rgb.png\")\n",
    "\n",
    "\n",
    "# Initialize a new list to store the results\n",
    "# result = []\n",
    "# for i, v in enumerate(range(0, 960, 31)):\n",
    "#     # print(i, v)\n",
    "#     if (i % 2 == 0 and i != 30):\n",
    "#         result.extend(range(v, v+30, 2))  # Take 15 elements\n",
    "#     if i == 15:\n",
    "#         result.extend(range(v+1, v+30, 2))  # Take 15 elements\n",
    "        \n",
    "# result = []\n",
    "# index = 0\n",
    "# for i, v in enumerate(range(0, 960, 31)):\n",
    "#     result.append(list(range(v, v+31)))  # Take 15 elements\n",
    "\n",
    "# final = []\n",
    "# for y in range(0, len(result), 5):\n",
    "#     for x in range(0, len(result[y]), 5):\n",
    "#         shutil.copy(r\"d:\\Research\\De-Blurring\\Scene_51\\FS\\TD_pose_\"+str(result[y][x])+\"_rgb.png\", \n",
    "#             r\"d:\\Research\\De-Blurring\\Scene_51\\FS_8\\TD_pose_\"+str(result[y][x])+\"_rgb.png\")\n",
    "         \n",
    "   \n",
    "# for img in result: \n",
    "#     shutil.copy(r\"d:\\Research\\De-Blurring\\Scene_51\\FS\\TD_pose_\"+str(img)+\"_rgb.png\", \n",
    "#                 r\"d:\\Research\\De-Blurring\\Scene_51\\FS_15\\TD_pose_\"+str(img)+\"_rgb.png\")\n",
    "\n",
    "folder_path2 = r\"d:\\Research\\De-Blurring\\codes\\SOD-Pytorch\\data\\test\\Scene_41\\FS_9\"\n",
    "# mona = 0\n",
    "# for i in result:\n",
    "#     mona += 1\n",
    "#     print(\"{:4}\".format(i), end=\" \")\n",
    "#     if mona % 15 == 0 and mona != 0:\n",
    "#         print()\n",
    "# print(len(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "imagelist = []\n",
    "center_index = 0\n",
    "check = True\n",
    "for img in sorted(glob.glob(folder_path + '/*.png'),key=numericalSort):      # Enter path to the images directory which should contain 11 images.\n",
    "    if \"TD_pose_40_rgb\" not in img and check:\n",
    "        center_index += 1\n",
    "    else:\n",
    "        check = False\n",
    "    # print(img)\n",
    "    n= cv2.imread(img)\n",
    "    imagelist.append(n)  \n",
    "site_poses = []\n",
    "print(center_index)\n",
    "# Below is the poses computation from x,y coordinates to a transformation matrix to load into the renderer.\n",
    "    \n",
    "for i in range(len(imagelist)):   # 2 because we are only dealing with 2 images/poses for every iteration.\n",
    "    #For Bottom Up comment the following 2 lines and add - to image_posey\n",
    "    EastCentered = (image_posx[i] - 0.0) \n",
    "    NorthCentered = (0.0 - image_posy[i]) \n",
    "    M = createviewmateuler(np.array([0.0, 0.0, 0.0]),np.array( [image_posx[i], image_posy[i], image_posz[i] ] )) # z = -35 for all images\n",
    "    #print('m',M)\n",
    "    ViewMatrix = np.vstack((M, np.array([0.0,0.0,0.0,1.0],dtype=np.float32)))\n",
    "    #print(ViewMatrix)\n",
    "    camerapose = np.asarray(ViewMatrix.transpose(),dtype=np.float32)\n",
    "    #print(camerapose)\n",
    "    site_poses.append(camerapose) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Note the altitude in poses is set as -35, the z axis is positive going downwards. So the focal plane value you have to set  will be in range 0 to -35 (0 for ground -35 the camera)    \n",
    "    \n",
    "center_index = len(imagelist) // 2 #480 Index or camera position at which you want to generate the integral image   \n",
    "aos.clearViews()   # Every time you call the renderer you should use this line to clear the previous views  \n",
    "for i in range(len(imagelist)):\n",
    "        aos.addView(imagelist[i], site_poses[i], \"DEM BlobTrack\")  # Here we are adding images to the renderer one by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-10.0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_posx[len(image_posx) //2]\n",
    "# print(len(image_posx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "Time taken = 21.294007301330566\n"
     ]
    }
   ],
   "source": [
    "######## If you want to do focal stack of integral images just put everything below in a loop where you keep updating the Focal_plane variable        \n",
    "focal = 0\n",
    "fs = []\n",
    "print(len(image_posx) //2)\n",
    "for i in range(550):\n",
    "    aos.setDEMTransform([0,0,focal])\n",
    "    proj_RGBimg = aos.render(pose_to_virtualcamera(site_poses[len(image_posx) //2]), render_fov)\n",
    "    #proj_RGBimg = aos.render(pose_to_virtualcamera(site_poses[center_index]), render_fov)\n",
    "    tmp_RGB = divide_by_alpha(proj_RGBimg)\n",
    "    # # control Contrast by 1.5 \n",
    "    # alpha = 0  \n",
    "    # # control brightness by 50 \n",
    "    # beta = 50  \n",
    "    # image2 = cv2.convertScaleAbs(tmp_RGB, alpha=alpha, beta=beta) \n",
    "    fs.append(tmp_RGB)\n",
    "    #  cv2.cvtColor(tmp_RGB, cv2.COLOR_BGR2GRAY)\n",
    "    cv2.imwrite(os.path.join( result_path, f'{str(i)}.png'), tmp_RGB)   # Final result. Check the integral result in the integrals folder.\n",
    "    focal -= 0.03\n",
    "\n",
    "print(f'Time taken = {time.time() - start_time}')\n",
    "# fs_copy = fs.copy()\n",
    "# index = 1\n",
    "# for i in (reversed(fs[1:])):\n",
    "#     # x = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "#     cv2.imwrite(os.path.join( result_path, f'{str(index)}.png'), i)   # Final result. Check the integral result in the integrals folder.\n",
    "#     index += 1\n",
    "\n",
    "\n",
    "# index = 6\n",
    "# for i in (fs):\n",
    "#     # x = cv2.cvtColor(i, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     cv2.imwrite(os.path.join( result_path, f'{str(index)}.png'), i)   # Final result. Check the integral result in the integrals folder.\n",
    "#     index += 1\n",
    "\n",
    "# Not used    \n",
    "\n",
    "\n",
    "# focal = -5\n",
    "# for i in range(50):\n",
    "#     aos.setDEMTransform([0,0,focal])\n",
    "#     proj_RGBimg = aos.render(pose_to_virtualcamera(site_poses[center_index]), render_fov)\n",
    "#     tmp_RGB = divide_by_alpha(proj_RGBimg)\n",
    "#     cv2.imwrite(os.path.join( result_path, f'{str(i)}.png'), tmp_RGB)   # Final result. Check the integral result in the integrals folder.\n",
    "#     focal += 0.01\n",
    "    \n",
    "# focal = 0\n",
    "# for i in range(50, 100):\n",
    "#     aos.setDEMTransform([0,0,focal])\n",
    "#     proj_RGBimg = aos.render(pose_to_virtualcamera(site_poses[center_index]), render_fov)\n",
    "#     tmp_RGB = divide_by_alpha(proj_RGBimg)\n",
    "#     cv2.imwrite(os.path.join( result_path, f'{str(i)}.png'), tmp_RGB)   # Final result. Check the integral result in the integrals folder.\n",
    "#     focal -= 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "del window\n",
    "\n",
    "del aos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@209.254] global loadsave.cpp:241 findDecoder imread_('d:\\Research\\De-Blurring\\Scene_51\\FP_8\\33.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@209.255] global loadsave.cpp:241 findDecoder imread_('d:\\Research\\De-Blurring\\Scene_51\\FP_16\\33.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@209.255] global loadsave.cpp:241 findDecoder imread_('d:\\Research\\De-Blurring\\Scene_51\\FP_31\\33.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_39934/4210072893.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mimage1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mimage2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mimage3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.10.0) /io/opencv/modules/imgproc/src/color.cpp:196: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "image1 = cv2.imread(r\"d:\\Research\\De-Blurring\\Scene_51\\FP_8\\33.png\")\n",
    "image2 = cv2.imread(r\"d:\\Research\\De-Blurring\\Scene_51\\FP_16\\33.png\")\n",
    "image3 = cv2.imread(r\"d:\\Research\\De-Blurring\\Scene_51\\FP_31\\33.png\")\n",
    "\n",
    "\n",
    "image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "image3 = cv2.cvtColor(image3, cv2.COLOR_BGR2GRAY)\n",
    "# print(image1[50][50])\n",
    "# print(image2[50][50])\n",
    "# print(image3[50][50])\n",
    "\n",
    "matrix = [[0 for _ in range(960)] for _ in range(960)]\n",
    "\n",
    "for i in range(960):\n",
    "    for j in range(960):\n",
    "        vectors = []\n",
    "        vectors.append(image1[i][j])\n",
    "        vectors.append(image2[i][j])\n",
    "        vectors.append(image3[i][j])\n",
    "        vectors = np.array(vectors)\n",
    "        \n",
    "        matrix[i][j] = np.max(vectors - np.mean(vectors))\n",
    "\n",
    "# image1 = (image1 - image1.min()) / (image1.max() - image1.min())\n",
    "# image2 = (image2 - image2.min()) / (image2.max() - image2.min())\n",
    "\n",
    "# Convert images to float32 for accurate subtraction\n",
    "# image1_float = image1.astype(np.float32)\n",
    "# image2_float = image2.astype(np.float32)\n",
    "\n",
    "# # Perform element-wise subtraction\n",
    "# subtracted_image = np.abs(image1_float - image2_float)\n",
    "\n",
    "# Convert the result back to uint8 format\n",
    "# subtracted_image = subtracted_image.astype(np.uint8)\n",
    "from PIL import Image\n",
    "\n",
    "pixel_values = [[int(value) * 15 for value in row] for row in matrix]\n",
    "\n",
    "image = Image.new('L', (len(matrix[0]), len(matrix)))\n",
    "image.putdata([pixel for row in pixel_values for pixel in row])\n",
    "\n",
    "# Save the image\n",
    "image.save(r'd:\\Research\\De-Blurring\\Scene_51\\matrix_image.png')\n",
    "\n",
    "\n",
    "\n",
    "# If you want to save the result\n",
    "# cv2.imwrite(r\"d:\\Research\\De-Blurring\\Scene_51\\333.png\", subtracted_image * 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image1 = cv2.imread(r\"d:\\Research\\De-Blurring\\Scene_1\\inverted_mask\\TD38_pose_0_rgb.png\")\n",
    "image2 = cv2.imread(r\"d:\\Research\\De-Blurring\\Scene_1\\6.png\")\n",
    "\n",
    "image1 = image1[2:-2, 2:-2]\n",
    "\n",
    "# image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "# image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "image1 = (image1 - image1.min()) / (image1.max() - image1.min())\n",
    "image2 = (image2 - image2.min()) / (image2.max() - image2.min())\n",
    "\n",
    "cv2.imwrite(r\"d:\\Research\\De-Blurring\\Scene_1\\sss.png\", abs(image1 - image2) * 255)\n",
    "# cv2.imwrite(r\"d:\\Research\\De-Blurring\\Scene_1\\sss.png\", image1 * image2 * 255)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
